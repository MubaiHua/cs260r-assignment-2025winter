{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS260R Reinforcement Learning Assignment 0: Jupyter Notebook usage and assignment submission workflow\n",
    "\n",
    "------\n",
    "\n",
    "*CS260R: Reinforcement Learning. Department of Computer Science at University of California, Los Angeles.\n",
    "Course Instructor: Professor Bolei ZHOU. Assignment author: Zhenghao PENG.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are asked to finish four tasks:\n",
    "\n",
    "1. Fill in your name and University ID in the next cell.\n",
    "2. Install pytorch and finish the [Kindergarten Pytorch](Kindergarten Pytorch) section.\n",
    "3. Run all cells and export this notebook **as a PDF file**.\n",
    "4. Compress this folder `assignment0` **as a ZIP file** and submit **the PDF file and the ZIP file separately as two files** in BruinLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill your name and UID here\n",
    "my_name = \"Mubai Hua\"\n",
    "my_student_id = \"905571231\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I finished this assignment! I am Mubai Hua (905571231)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without modification\n",
    "\n",
    "text = \"Oh, I finished this assignment! I am {} ({})\".format(my_name, my_student_id)\n",
    "print(text)\n",
    "with open(\"{}.txt\".format(text), \"w\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kindergarten Pytorch\n",
    "\n",
    "1. Please install pytorch in your virtual environment following the instruction: [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/).\n",
    "```\n",
    "pip install torch torchvision\n",
    "```\n",
    "2. If you are not familiar with Pytorch, please go through [the tutorial in official website](https://pytorch.org/tutorials/beginner/basics/intro.html) until you can understand the [quick start tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html).\n",
    "3. The following code is copied from the [quick start tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html), please solve all `TODO`s and print the result in the cells before generating the PDF file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\r9000x-2021\\anaconda3\\envs\\cs260r\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# You can also run this cell in notebook:\n",
    "\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # TODO: Define the self.linear_relu_stack by uncommenting next few lines\n",
    "        # and understand what they mean\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and test pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "\n",
    "        # TODO: Uncomment next three lines and understand what they mean\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # TODO: Uncomment next line and understand what it means\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training and test pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300956  [   64/60000]\n",
      "loss: 2.290339  [ 6464/60000]\n",
      "loss: 2.262995  [12864/60000]\n",
      "loss: 2.261135  [19264/60000]\n",
      "loss: 2.251179  [25664/60000]\n",
      "loss: 2.212415  [32064/60000]\n",
      "loss: 2.228665  [38464/60000]\n",
      "loss: 2.184602  [44864/60000]\n",
      "loss: 2.182182  [51264/60000]\n",
      "loss: 2.172390  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 2.150298 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.156924  [   64/60000]\n",
      "loss: 2.151670  [ 6464/60000]\n",
      "loss: 2.089000  [12864/60000]\n",
      "loss: 2.108562  [19264/60000]\n",
      "loss: 2.069667  [25664/60000]\n",
      "loss: 2.005252  [32064/60000]\n",
      "loss: 2.033814  [38464/60000]\n",
      "loss: 1.953695  [44864/60000]\n",
      "loss: 1.953263  [51264/60000]\n",
      "loss: 1.902689  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 1.887714 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.919424  [   64/60000]\n",
      "loss: 1.892962  [ 6464/60000]\n",
      "loss: 1.771802  [12864/60000]\n",
      "loss: 1.812960  [19264/60000]\n",
      "loss: 1.714339  [25664/60000]\n",
      "loss: 1.663552  [32064/60000]\n",
      "loss: 1.681090  [38464/60000]\n",
      "loss: 1.579933  [44864/60000]\n",
      "loss: 1.600514  [51264/60000]\n",
      "loss: 1.507567  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 1.516864 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.584322  [   64/60000]\n",
      "loss: 1.549750  [ 6464/60000]\n",
      "loss: 1.394725  [12864/60000]\n",
      "loss: 1.469310  [19264/60000]\n",
      "loss: 1.353618  [25664/60000]\n",
      "loss: 1.345411  [32064/60000]\n",
      "loss: 1.359520  [38464/60000]\n",
      "loss: 1.280375  [44864/60000]\n",
      "loss: 1.316883  [51264/60000]\n",
      "loss: 1.224042  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.246329 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.323764  [   64/60000]\n",
      "loss: 1.304758  [ 6464/60000]\n",
      "loss: 1.136304  [12864/60000]\n",
      "loss: 1.245611  [19264/60000]\n",
      "loss: 1.122009  [25664/60000]\n",
      "loss: 1.142868  [32064/60000]\n",
      "loss: 1.165937  [38464/60000]\n",
      "loss: 1.099485  [44864/60000]\n",
      "loss: 1.141156  [51264/60000]\n",
      "loss: 1.063916  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.081099 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R9000X-2021\\AppData\\Local\\Temp\\ipykernel_19224\\2085806346.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs260r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
